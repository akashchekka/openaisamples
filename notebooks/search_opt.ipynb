{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_service_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "search_service_key = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\", \"\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_dimensions = int(os.getenv(\"AZURE_OPENAI_EMBEDDING_DIMENSIONS\", 1024))\n",
    "embedding_model_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-06-01\")\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\", \"\")\n",
    "base_index_name = 'scorp-opt'\n",
    "\n",
    "cohere_int8 = \"Collection(Edm.SByte)\"\n",
    "cohere_ubinary = \"Collection(Edm.Byte)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "cohere_client = cohere.Client(cohere_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_cohere(texts, input_type=\"search_document\", embedding_type=\"ubinary\"):\n",
    "    model = \"embed-english-v3.0\"\n",
    "\n",
    "    texts = [texts] if isinstance(texts, str) else texts\n",
    "\n",
    "    response = cohere_client.embed(\n",
    "        texts=texts,\n",
    "        model=model,\n",
    "        input_type=input_type,\n",
    "        embedding_types=[embedding_type],\n",
    "    )\n",
    "\n",
    "    res = [embedding for embedding in getattr(response.embeddings, embedding_type)]\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "        azure_deployment=azure_openai_embedding_deployment,\n",
    "        api_version=azure_openai_api_version,\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        api_key=azure_openai_key\n",
    "    )\n",
    "\n",
    "def get_embeddings(text):\n",
    "    response = openai_client.embeddings.create(input=text, model=embedding_model_name, dimensions=azure_openai_embedding_dimensions)\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akashchekka\\source\\repos\\AzureOpenAI\\RAG\\.venv\\Lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "file_path = '../files/QML-DS.pdf'\n",
    "\n",
    "pdf_content = PdfReader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for i, page in enumerate(pdf_content.pages):\n",
    "    text = page.extract_text()\n",
    "    \n",
    "    documents.append({\n",
    "        \"id\": str(i + 1),\n",
    "        \"title\": \"QLM-DS\",\n",
    "        \"category\": \"QML\",\n",
    "        \"content\": text,\n",
    "        \"contentVector\": get_embeddings(text)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cohere_embedded_documents(embedding_type):\n",
    "    cohere_documents = []\n",
    "\n",
    "    for i, page in enumerate(pdf_content.pages):\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        cohere_documents.append({\n",
    "            \"id\": str(i + 1),\n",
    "            \"title\": \"QLM-DS\",\n",
    "            \"category\": \"QML\",\n",
    "            \"content\": text,\n",
    "            \"contentVector\": get_embeddings_cohere(text, embedding_type=embedding_type)\n",
    "        })\n",
    "\n",
    "    return cohere_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    ScalarQuantizationCompression,\n",
    "    BinaryQuantizationCompression,\n",
    "    VectorSearchCompression,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    HnswParameters,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    VectorEncodingFormat\n",
    ")\n",
    "\n",
    "def create_index(index_name, dimensions, cohere_vector_type, use_scalar_compression=False, use_binary_compression=False, use_float16=False, use_stored=True, use_cohere=False, truncate_dimensions=None):\n",
    "    if not use_cohere:\n",
    "        if use_float16:\n",
    "            vector_type = \"Collection(Edm.Half)\"\n",
    "        else:\n",
    "            vector_type = \"Collection(Edm.Single)\"\n",
    "\n",
    "    fields = [\n",
    "        SimpleField(\n",
    "            name=\"id\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            key=True,\n",
    "            sortable=True,\n",
    "            filterable=True,\n",
    "            facetable=True\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"title\",\n",
    "            type=SearchFieldDataType.String\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"category\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            filterable=True\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"content\",\n",
    "            type=SearchFieldDataType.String\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"contentVector\",\n",
    "            type=vector_type if cohere_vector_type is None else cohere_vector_type,\n",
    "            searchable=True,\n",
    "            stored=use_stored,\n",
    "            vector_search_dimensions=dimensions,\n",
    "            vector_search_profile_name=\"myHnswProfile\",\n",
    "            vector_encoding_format=(\n",
    "                VectorEncodingFormat.PACKED_BIT\n",
    "                if cohere_vector_type == \"Collection(Edm.Byte)\"\n",
    "                else None\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    compression_configurations: List[VectorSearchCompression] = []\n",
    "    if use_scalar_compression:\n",
    "        compression_name = \"myCompression\"\n",
    "        compression_configurations = [\n",
    "            ScalarQuantizationCompression(\n",
    "                compression_name=compression_name,\n",
    "                truncation_dimension=truncate_dimensions\n",
    "            )\n",
    "        ]\n",
    "    elif use_binary_compression:\n",
    "        compression_name = \"myCompression\"\n",
    "        compression_configurations = [\n",
    "            BinaryQuantizationCompression(\n",
    "                compression_name=compression_name,\n",
    "                rerank_with_original_vectors=True,\n",
    "                truncation_dimension=truncate_dimensions\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        compression_name = None\n",
    "        compression_configurations = []\n",
    "    \n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"myHnsw\",\n",
    "                kind=VectorSearchAlgorithmKind.HNSW,\n",
    "                parameters=HnswParameters(\n",
    "                    metric=(\n",
    "                        VectorSearchAlgorithmMetric.HAMMING\n",
    "                        if cohere_vector_type == \"Collection(Edm.Byte)\"\n",
    "                        else VectorSearchAlgorithmMetric.COSINE\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"myHnswProfile\",\n",
    "                algorithm_configuration_name=\"myHnsw\",\n",
    "                compression_name=compression_name\n",
    "            )\n",
    "        ],\n",
    "        compressions=compression_configurations\n",
    "    )\n",
    "\n",
    "    semantic_config = SemanticConfiguration(\n",
    "        name=\"my-semantic-config\",\n",
    "        prioritized_fields=SemanticPrioritizedFields(\n",
    "            title_field=SemanticField(field_name=\"title\"),\n",
    "            content_fields=[SemanticField(field_name=\"content\")]\n",
    "        )\n",
    "    )\n",
    "    semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "    return SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created indexes\n"
     ]
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "baseline_index = f\"{base_index_name}-baseline\"\n",
    "scalar_compression_index = f\"{base_index_name}-scalar-compression\"\n",
    "binary_compression_index = f\"{base_index_name}-binary-compression\"\n",
    "narrow_index = f\"{base_index_name}-narrow\"\n",
    "no_stored_index = f\"{base_index_name}-no-stored\"\n",
    "cohere_index_ubinary = f\"{base_index_name}-cohere-ubinary\"\n",
    "cohere_index_int8 = f\"{base_index_name}-cohere-int8\"\n",
    "all_index_scalar = f\"{base_index_name}-all-options-with-scalar\"\n",
    "all_index_binary = f\"{base_index_name}-all-options-with-binary\"\n",
    "\n",
    "search_index_client = SearchIndexClient(search_service_endpoint, AzureKeyCredential(search_service_key))\n",
    "search_index_client.create_or_update_index(\n",
    "    create_index(scalar_compression_index, azure_openai_embedding_dimensions, None, use_scalar_compression=True))\n",
    "search_index_client.create_or_update_index(\n",
    "    create_index(binary_compression_index, azure_openai_embedding_dimensions, None, use_binary_compression=True))\n",
    "search_index_client.create_or_update_index(\n",
    "    create_index(narrow_index, azure_openai_embedding_dimensions, None, use_float16=True))\n",
    "search_index_client.create_or_update_index(\n",
    "    create_index(no_stored_index, azure_openai_embedding_dimensions, None, use_stored=False))\n",
    "search_index_client.create_or_update_index(\n",
    "    create_index(all_index_scalar, azure_openai_embedding_dimensions, None, use_scalar_compression=True, use_float16=True, use_stored=False))\n",
    "search_index_client.create_or_update_index(\n",
    "    create_index(all_index_binary, azure_openai_embedding_dimensions, None, use_binary_compression=True, use_float16=True, use_stored=False))\n",
    "search_index_client.create_or_update_index(\n",
    "    create_index(baseline_index, azure_openai_embedding_dimensions, None))\n",
    "search_index_client.create_or_update_index(\n",
    "    create_index(cohere_index_ubinary, 1024, cohere_ubinary, use_cohere=True, use_stored=True))\n",
    "search_index_client.create_or_update_index(\n",
    "    create_index(cohere_index_int8, 1024, cohere_int8, use_cohere=True, use_stored=True))\n",
    "\n",
    "print(\"Created indexes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "def upload_embeddings(index_name, documents):    \n",
    "    with SearchIndexingBufferedSender(search_service_endpoint, index_name, AzureKeyCredential(search_service_key)) as client:\n",
    "        client.upload_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload ada embedded documents\n",
    "upload_embeddings(scalar_compression_index, documents)\n",
    "upload_embeddings(binary_compression_index, documents)\n",
    "upload_embeddings(narrow_index, documents)\n",
    "upload_embeddings(no_stored_index, documents)\n",
    "upload_embeddings(all_index_scalar, documents)\n",
    "upload_embeddings(all_index_binary, documents)\n",
    "upload_embeddings(baseline_index, documents)\n",
    "\n",
    "# Upload cohere embedded documents\n",
    "upload_embeddings(cohere_index_ubinary, get_cohere_embedded_documents(\"ubinary\"))\n",
    "upload_embeddings(cohere_index_int8, get_cohere_embedded_documents(\"int8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Index Name: scorp-opt-scalar-compression\n",
      "Storage Size: 1.6637MB\n",
      "Vector Size: 0.2732MB\n",
      "****************************************\n",
      "Index Name: scorp-opt-baseline\n",
      "Storage Size: 1.6628MB\n",
      "Vector Size: 0.2732MB\n",
      "****************************************\n",
      "Index Name: scorp-opt-binary-compression\n",
      "Storage Size: 1.4031MB\n",
      "Vector Size: 0.0121MB\n",
      "****************************************\n",
      "Index Name: scorp-opt-narrow\n",
      "Storage Size: 1.3933MB\n",
      "Vector Size: 0.1384MB\n",
      "****************************************\n",
      "Index Name: scorp-opt-no-stored\n",
      "Storage Size: 1.096MB\n",
      "Vector Size: 0.2732MB\n",
      "****************************************\n",
      "Index Name: scorp-opt-all-options-with-scalar\n",
      "Storage Size: 0.8275MB\n",
      "Vector Size: 0.1384MB\n",
      "****************************************\n",
      "Index Name: scorp-opt-cohere-int8\n",
      "Storage Size: 0.758MB\n",
      "Vector Size: 0.0486MB\n",
      "****************************************\n",
      "Index Name: scorp-opt-all-options-with-binary\n",
      "Storage Size: 0.7016MB\n",
      "Vector Size: 0.0121MB\n",
      "****************************************\n",
      "Index Name: scorp-opt-cohere-ubinary\n",
      "Storage Size: 0.5845MB\n",
      "Vector Size: 0.0092MB\n"
     ]
    }
   ],
   "source": [
    "def bytes_to_mb(bytes):\n",
    "    return round(bytes / (1024 * 1024), 4)\n",
    "\n",
    "def find_storage_size_mb(index_name):\n",
    "    response = search_index_client.get_index_statistics(index_name)\n",
    "    return bytes_to_mb(response[\"storage_size\"]), bytes_to_mb(response[\"vector_index_size\"])\n",
    "\n",
    "index_sizes = [(find_storage_size_mb(index_name), index_name) for index_name in [\n",
    "                    scalar_compression_index,\n",
    "                    binary_compression_index,\n",
    "                    baseline_index,\n",
    "                    no_stored_index,\n",
    "                    narrow_index,\n",
    "                    cohere_index_ubinary,\n",
    "                    cohere_index_int8,\n",
    "                    all_index_scalar,\n",
    "                    all_index_binary\n",
    "                ]\n",
    "            ]\n",
    "index_sizes.sort(key=lambda item: item[0][0], reverse=True)\n",
    "\n",
    "for ((storage_size, vector_size), index_name) in index_sizes:\n",
    "    print(\"*\" * 40)\n",
    "    print(f\"Index Name: {index_name}\\nStorage Size: {storage_size}MB\\nVector Size: {vector_size}MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
